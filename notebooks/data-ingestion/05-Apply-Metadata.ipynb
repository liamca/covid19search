{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take the file and extract the journal dates and upload to Azure Cog Search index\n",
    "# https://azsdemos.blob.core.windows.net/covid-19/metadata.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import globals\n",
    "\n",
    "import csv\n",
    "from dateutil import parser\n",
    "\n",
    "import json\n",
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "metadata_file = \"/datadrive2/processed/content/metadata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying docs: 1000\n",
      "Applying docs: 2000\n",
      "Applying docs: 3000\n",
      "Applying docs: 4000\n",
      "Applying docs: 5000\n",
      "Applying docs: 6000\n",
      "Applying docs: 7000\n",
      "Applying docs: 8000\n",
      "Applying docs: 9000\n",
      "Applying docs: 10000\n",
      "Applying docs: 11000\n",
      "Applying docs: 12000\n",
      "Applying docs: 13000\n",
      "Applying docs: 14000\n",
      "Applying docs: 15000\n",
      "Applying docs: 16000\n",
      "Applying docs: 17000\n",
      "Applying docs: 18000\n",
      "Applying docs: 19000\n",
      "Applying docs: 20000\n",
      "Applying docs: 21000\n",
      "Applying docs: 22000\n",
      "Applying docs: 23000\n",
      "Applying docs: 24000\n",
      "Applying docs: 25000\n",
      "Applying docs: 26000\n",
      "Applying docs: 27000\n",
      "Applying docs: 28000\n",
      "Applying docs: 29000\n",
      "Applying docs: 30000\n",
      "Applying docs: 31000\n",
      "Applying docs: 32000\n",
      "Applying docs: 33000\n",
      "Applying docs: 34000\n",
      "Applying docs: 35000\n",
      "Applying docs: 36000\n",
      "Applying docs: 37000\n",
      "Applying docs: 38000\n",
      "Applying docs: 39000\n",
      "Applying docs: 40000\n",
      "Applying docs: 41000\n",
      "Applying docs: 42000\n",
      "Applying docs: 43000\n",
      "Applying docs: 44000\n",
      "Applying docs: 45000\n",
      "Applying docs: 46000\n",
      "Applying docs: 47000\n",
      "Applying docs: 48000\n",
      "Applying docs: 49000\n",
      "Applying docs: 50000\n",
      "Applying docs: 51000\n",
      "Applying docs: 52000\n",
      "Applying docs: 53000\n",
      "Applying docs: 54000\n",
      "Applying docs: 55000\n",
      "Applying docs: 56000\n",
      "Applying docs: 57000\n",
      "Applying docs: 58000\n",
      "Applying docs: 59000\n",
      "Applying docs: 60000\n",
      "Applying docs: 61000\n",
      "Applying docs: 62000\n",
      "Applying docs: 63000\n",
      "Applying docs: 64000\n",
      "Applying docs: 65000\n",
      "Applying docs: 66000\n",
      "Applying docs: 67000\n",
      "Applying docs: 68000\n",
      "Applying docs: 69000\n",
      "Applying docs: 70000\n",
      "Applying docs: 71000\n",
      "Applying docs: 72000\n",
      "Applying docs: 73000\n",
      "Applying docs: 74000\n",
      "Applying docs: 75000\n",
      "Applying docs: 76000\n",
      "Applying docs: 77000\n",
      "Applying docs: 78000\n",
      "Applying docs: 79000\n",
      "Applying docs: 80000\n",
      "Applying docs: 81000\n",
      "Applying docs: 82000\n",
      "Applying docs: 83000\n",
      "Applying docs: 84000\n",
      "Applying docs: 85000\n",
      "Applying docs: 86000\n",
      "Applying docs: 87000\n",
      "Applying docs: 88000\n",
      "Applying docs: 89000\n",
      "Applying docs: 90000\n",
      "Applying docs: 91000\n",
      "Applying docs: 92000\n",
      "Applying docs: 93000\n",
      "Applying docs: 94000\n",
      "Applying docs: 95000\n",
      "Applying docs: 96000\n",
      "Applying docs: 97000\n",
      "Applying docs: 98000\n",
      "Applying docs: 99000\n",
      "Applying docs: 100000\n",
      "Applying docs: 101000\n",
      "Applying docs: 102000\n",
      "Applying docs: 103000\n",
      "Applying docs: 104000\n",
      "Applying docs: 105000\n",
      "Applying docs: 106000\n",
      "Applying docs: 107000\n",
      "Applying docs: 108000\n",
      "Applying docs: 109000\n",
      "Applying docs: 110000\n",
      "Applying docs: 111000\n",
      "Applying docs: 112000\n",
      "Applying docs: 112847\n"
     ]
    }
   ],
   "source": [
    "documents = {\"value\": []}\n",
    "doc_counter = 0\n",
    "batch_size = 1000\n",
    "\n",
    "row_counter = 0\n",
    "with open(metadata_file, newline='', encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        split_sha = row['sha'].split(';')\n",
    "        \n",
    "        # Sometimes the metadata can have two doc's in a single row\n",
    "        for sha in split_sha:\n",
    "            docID = ''\n",
    "            pubDate = ''\n",
    "            journal = ''\n",
    "            fullTextURL = ''\n",
    "            searchJSON = {\"@search.action\": \"merge\"}\n",
    "            if len(sha.strip()) > 1:\n",
    "                doc_counter += 1\n",
    "\n",
    "                try:\n",
    "                    docID = sha.strip()\n",
    "                    searchJSON[\"docID\"] = docID\n",
    "\n",
    "                    pubDate = row['publish_time']\n",
    "                    \n",
    "                    if len(pubDate) > 11:\n",
    "                        pubDate = parser.parse(pubDate[:8]).strftime('%Y-%m-%d') + 'T12:00:00Z'\n",
    "                    elif len(pubDate) == 4:\n",
    "                        pubDate = parser.parse(pubDate[:4]+\"-01-01\").strftime('%Y-%m-%d') + 'T12:00:00Z'\n",
    "                    else:\n",
    "                        pubDate = parser.parse(pubDate).strftime('%Y-%m-%d') + 'T12:00:00Z'\n",
    "                    searchJSON[\"pubDate\"] = pubDate\n",
    "                    \n",
    "                    searchJSON[\"journal\"] = row['journal']\n",
    "                    searchJSON[\"fullTextURL\"] = row['url']\n",
    "                    \n",
    "                    documents[\"value\"].append(searchJSON)\n",
    "                    \n",
    "\n",
    "                except Exception as ex:\n",
    "                    print (\"Error: \", ex)\n",
    "                    \n",
    "                if doc_counter % batch_size == 0:\n",
    "                    print (\"Applying docs:\", doc_counter)\n",
    "                    url = globals.endpoint + \"indexes/\" + globals.indexName + \"/docs/index\" + globals.api_version\n",
    "                    response  = requests.post(url, headers=globals.headers, json=documents)\n",
    "                    documents = {\"value\": []}\n",
    "    \n",
    "    \n",
    "\n",
    "if doc_counter > 0:\n",
    "    print (\"Applying docs:\", doc_counter)\n",
    "    url = globals.endpoint + \"indexes/\" + globals.indexName + \"/docs/index\" + globals.api_version\n",
    "    response  = requests.post(url, headers=globals.headers, json=documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_default",
   "language": "python",
   "name": "conda-env-py37_default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
